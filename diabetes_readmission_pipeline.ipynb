{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Hospital Readmission for Diabetes Patients\n",
    "\n",
    "## Objective\n",
    "Demonstrate an end-to-end machine learning pipeline to predict whether a patient will be readmitted to a hospital after a diabetes diagnosis using data maintained by UCI detailing 10 years of clinical care at U.S. hospitals and integrated delivery networks.\n",
    "\n",
    "## Table of Contents\n",
    "* [Data Loading](#data_loading)\n",
    "* [Data Cleaning & Preprocessing](#data_cleaning)\n",
    "* [Exploratory Data Analysis (EDA)](#eda)\n",
    "    * [Expore numeric data](#eda_numeric)\n",
    "    * [Explore categorical data](#eda_categorical)\n",
    "* [Feature Engineering](#feature_engineering)\n",
    "* [Model Training & Evaluation](#model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "import requests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading <a class=\"anchor\" id=\"data_loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/296/diabetes+130-us+hospitals+for+years+1999-2008.zip\"\n",
    "\n",
    "try:\n",
    "    print(\"Downloading dataset...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status() # raises error for bad HTTP responses\n",
    "\n",
    "    print(\"Download successful! Extracting files...\")\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(response.content)) # open ZIP in memory\n",
    "\n",
    "    # list the files\n",
    "    files_list = zip_file.namelist()\n",
    "    print(\"Files contained in ZIP:\\n\", \", \".join(files_list))\n",
    "\n",
    "    # create a dictionary to store the files\n",
    "    files = {}\n",
    "\n",
    "    for file_name in files_list:\n",
    "        with zip_file.open(file_name) as f:\n",
    "            files[file_name] = pd.read_csv(f)\n",
    "\n",
    "    # assign the DataFrames to variables\n",
    "    df_diabetes = files.get(\"diabetic_data.csv\")\n",
    "    df_ids = files.get(\"IDS_mapping.csv\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading dataset: {e}\")\n",
    "\n",
    "    # TODO: Possibly comment out the next three lines\n",
    "    print(\"Retrieving from local directory...\")\n",
    "    df_diabetes = pd.read_csv(\"~/Downloads/diabetes+130-us+hospitals+for+years+1999-2008/diabetic_data.csv\")\n",
    "    df_ids = pd.read_csv(\"~/Downloads/diabetes+130-us+hospitals+for+years+1999-2008/IDS_mapping.csv\")\n",
    "\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error processing ZIP file\")\n",
    "\n",
    "except OSError as e:\n",
    "    print(f\"Error opening file: {e}\")\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error retrieving file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preprocessing <a class=\"anchor\" id=\"data_cleaning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the IDs DF for merging\n",
    "df_ids.dropna(inplace=True)\n",
    "df_filtered_ids = df_ids[df_ids[\"admission_type_id\"].str.isdigit()].copy()\n",
    "df_grouped_ids = df_filtered_ids.groupby(\"admission_type_id\")[\"description\"].apply(lambda x: \" | \".join(x)).reset_index()\n",
    "\n",
    "# prepare the diabetes DF for merging\n",
    "df_diabetes[\"admission_type_id\"] = df_diabetes[\"admission_type_id\"].astype(str)\n",
    "\n",
    "# merge the DFs\n",
    "df = df_diabetes.merge(df_grouped_ids, how=\"left\", on=\"admission_type_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify columns using a question mark as a null value\n",
    "question_mark_cols = \", \".join(df.columns[(df == \"?\").any()])\n",
    "print(\"Columns using \\\"?\\\" to signify null values:\\n\", question_mark_cols)\n",
    "\n",
    "# replace \"?\" rows with NaN\n",
    "df.where(df != \"?\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_missing_value_columns(df):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing null statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    # get columns and their missing value counts\n",
    "    missing_values = df.isna().sum()\n",
    "    missing_values = missing_values[missing_values > 0].reset_index()\n",
    "\n",
    "    # rename the columns and calculate the percentage of nulls\n",
    "    missing_values.columns = [\"column_name\", \"null_count\"]\n",
    "    missing_values[\"null_perc\"] = missing_values[\"null_count\"] / df.shape[0]\n",
    "\n",
    "    # sort the values\n",
    "    missing_values.sort_values(by=\"null_perc\", ascending=False, inplace=True)\n",
    "\n",
    "    return missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DF showing missing value statistics\n",
    "display_missing_value_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with 30% or more values missing\n",
    "non_na_vals = df.shape[0] - (0.3 * df.shape[0])\n",
    "df.dropna(thresh=non_na_vals, axis=1, inplace=True)\n",
    "\n",
    "# drop the remaining null rows\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "print(f\"Total duplicate rows: {df.duplicated().sum()}\")\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate patient numbers (i.e., more than one encounter per patient)\n",
    "grouped_patient_nbrs = df.groupby(\"patient_nbr\")[\"encounter_id\"].count().reset_index()\n",
    "grouped_patient_nbrs.sort_values(by=\"encounter_id\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort to keep only the patient number for the most recent encounter\n",
    "df.sort_values(by=[\"patient_nbr\", \"encounter_id\"], ascending=[True, False], inplace=True)\n",
    "df.drop_duplicates(subset=\"patient_nbr\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast any identifer columns to an object type\n",
    "cols_to_convert = df.filter(regex=r\"_(?:id|nbr)$\").columns\n",
    "df[cols_to_convert] = df[cols_to_convert].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data to keep only readmissions within a month\n",
    "df = df[df[\"readmitted\"].ne(\">30\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_icd9_to_category(code):\n",
    "    \"\"\"Maps ICD-9 codes to disease categories.\n",
    "\n",
    "    Args:\n",
    "        code (str): A string value representing an ICD-9 code.\n",
    "    Returns:\n",
    "        str: A string value representing a disease classification.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        code = str(code).strip()\n",
    "        if code.startswith(\"250\"):\n",
    "            category =  \"Diabetes-Related\"\n",
    "        elif code.startswith(\"E\"):\n",
    "            category =  \"Supplementary Classification of External Causes of Injury and Poisoning\"\n",
    "        elif code.startswith(\"V\"):\n",
    "            category =  \"Supplementary Classification of Factors influencing Health Status and Contact with Health Services\"\n",
    "\n",
    "        code = int(float(code))\n",
    "        if 1 <= code <= 139:\n",
    "            category =  \"Infectious and Parasitic Diseases\"\n",
    "        elif 140 <= code <= 239:\n",
    "            category =  \"Neoplasms\"\n",
    "        elif 240 <= code <= 279:\n",
    "            category =  \"Endocrine, Nutritional and Metabolic Diseases, and Immunity Disorders\"\n",
    "        elif 280 <= code <= 289:\n",
    "            category =  \"Diseases of the Blood and Blood-forming Organs\"\n",
    "        elif 290 <= code <= 319:\n",
    "            category =  \"Mental Disorders\"\n",
    "        elif 320 <= code <= 389:\n",
    "            category =  \"Diseases of the Nervous System and Sense Organs\"\n",
    "        elif 390 <= code <= 459:\n",
    "            category =  \"Diseases of the Circulatory System\"\n",
    "        elif 460 <= code <= 519:\n",
    "            category =  \"Diseases of the Respiratory System\"\n",
    "        elif 520 <= code <= 579:\n",
    "            category =  \"Diseases of the Digestive System\"\n",
    "        elif 580 <= code <= 629:\n",
    "            category =  \"Diseases of the Genitourinary System\"\n",
    "        elif 630 <= code <= 679:\n",
    "            category =  \"Complications of Pregnancy, Childbirth, and the Puerperium\"\n",
    "        elif 680 <= code <= 709:\n",
    "            category =  \"Diseases of the Skin and Subcutaneous Tissue\"\n",
    "        elif 710 <= code <= 739:\n",
    "            category =  \"Diseases of the Musculoskeletal System and Connective Tissue\"\n",
    "        elif 740 <= code <= 759:\n",
    "            category =  \"Congenital Anomalies\"\n",
    "        elif 760 <= code <= 779:\n",
    "            category =  \"Certain Conditions originating in the Perinatal Period\"\n",
    "        elif 780 <= code <= 799:\n",
    "            category =  \"Symptoms, Signs and Ill-defined Conditions\"\n",
    "        elif 800 <= code <= 999:\n",
    "            category =  \"Injury and Poisoning\"\n",
    "        else:\n",
    "            category =  \"Other\"\n",
    "\n",
    "    except:\n",
    "        category =  \"Other\"\n",
    "\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ICD-9 codes to disease categories\n",
    "df[[\"disease_class_1\", \"disease_class_2\", \"disease_class_3\"]] = df[[\"diag_1\", \"diag_2\", \"diag_3\"]].apply(lambda col: col.map(map_icd9_to_category, na_action=\"ignore\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>\n",
    "\n",
    "### Explore numeric data <a class=\"anchor\" id=\"eda_numeric\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at descriptive statistics for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_distributions(df):\n",
    "    \"\"\"Generates a grid of boxplots and histograms for numeric columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset with numeric data.\n",
    "    \"\"\"\n",
    "\n",
    "    # identify numeric columns\n",
    "    numeric_cols = sorted(df.select_dtypes(include=\"number\").columns)\n",
    "\n",
    "    # get the number of numeric columns\n",
    "    num_cols = len(numeric_cols)\n",
    "\n",
    "    # create a figure and set of subplots\n",
    "    fig, axes = plt.subplots(num_cols, 2, figsize=(10, 5 * num_cols))\n",
    "\n",
    "    # create a side-by-side boxplot and histogram for each row\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        sns.boxplot(data=df, x=col, color=\"mediumvioletred\", ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"Boxplot of {col}\")\n",
    "\n",
    "        sns.histplot(data=df, x=col, color=\"lightcoral\", ax=axes[i, 1])\n",
    "        axes[i, 1].set_title(f\"Histogram of {col}\")\n",
    "\n",
    "    # prevent overlap and display figure\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the distributions in the numeric data\n",
    "plot_numeric_distributions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_skewness_columns(df):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' skewness.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset containing numeric data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing skewness values.\n",
    "    \"\"\"\n",
    "\n",
    "    # check for skewness and rename columns\n",
    "    skewness = df.select_dtypes(include=\"number\").skew().reset_index()\n",
    "    skewness.columns = [\"column_name\", \"value\"]\n",
    "\n",
    "    # categorize the skewness\n",
    "    conditions = [skewness[\"value\"].abs().between(0.5, 1), skewness[\"value\"].abs() > 1]\n",
    "    choices = [\"Moderate\", \"High\"]\n",
    "    skewness[\"skew_category\"] = np.select(conditions, choices, default=\"Symmetric\")\n",
    "\n",
    "    # sort the values\n",
    "    skewness.sort_values(by=\"value\", ascending=False, inplace=True)\n",
    "\n",
    "    return skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DF showing skewness\n",
    "display_skewness_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the strength of relationships among numeric columns\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_df = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr_df, cmap=\"PuRd\", annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore categorical data <a class=\"anchor\" id=\"eda_categorical\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at descriptive statistics for categorical columns\n",
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cardinality_columns(df):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' cardinality.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing cardinality statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    # get columns and their number of unique values\n",
    "    cardinal_values = df.select_dtypes(include=[\"category\", \"object\"]).nunique().reset_index()\n",
    "\n",
    "    # rename the columns and categorize the skewness\n",
    "    cardinal_values.columns = [\"column_name\", \"num_unique\"]\n",
    "    cardinal_values[\"cardinality\"] = cardinal_values[\"num_unique\"].apply(lambda x: \"Low\" if x < 15 else \"Moderate\" if 15 <= x < 50 else \"High\")\n",
    "\n",
    "    # sort the values\n",
    "    cardinal_values.sort_values(by=\"num_unique\", ascending=False, inplace=True)\n",
    "\n",
    "    return cardinal_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DF showing cardinality\n",
    "display_cardinality_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_distributions(df, threshold=5):\n",
    "    \"\"\"Generates a grid of violin and count plots for categorical columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset with categorical data.\n",
    "        threshold (int): The max number of unique values a column should have.\n",
    "    \"\"\"\n",
    "\n",
    "    # identify categorical columns and remove ID columns\n",
    "    unique_values = df.select_dtypes(include=[\"category\", \"object\"]).nunique()\n",
    "    categorical_cols = sorted(unique_values[unique_values.values <= threshold].index)\n",
    "\n",
    "    # get the number of categorical columns\n",
    "    num_cols = len(categorical_cols)\n",
    "\n",
    "    # create a figure and set of subplots\n",
    "    fig, axes = plt.subplots(num_cols, 2, figsize=(10, 5 * num_cols))\n",
    "\n",
    "    # create a side-by-side violin plot and count plot for each row\n",
    "    for i, col in enumerate(categorical_cols):\n",
    "\n",
    "        sns.violinplot(data=df, x=col, color=\"mediumvioletred\", ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"Boxplot of {col}\")\n",
    "        axes[i, 0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        sns.countplot(data=df, x=col, color=\"lightcoral\", ax=axes[i, 1])\n",
    "        axes[i, 1].set_title(f\"Histogram of {col}\")\n",
    "        axes[i, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # prevent overlap and display figure\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the distributions in the categorical data\n",
    "plot_categorical_distributions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_chi_square_columns(df, target_col):\n",
    "    \"\"\"Generates a DataFrame analyzing columns' null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataset containing categorical columns.\n",
    "        target_col (str): A variable that is being predicted on.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing chi-square and p-value statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    # get categorical columns, except for identifier columns and the target\n",
    "    categorical_cols = df.select_dtypes(include=[\"category\", \"object\"]).columns\n",
    "    categorical_df = df[categorical_cols].copy()\n",
    "    categorical_df.drop(columns=[\"encounter_id\", \"patient_nbr\", target_col], inplace=True)\n",
    "\n",
    "    # initialize a dictionary to hold the chi-square test results\n",
    "    result_dict = {\"column_name\": [], \"chi_sq\": [], \"p_val\": []}\n",
    "\n",
    "    for col in categorical_df:\n",
    "\n",
    "        # compute the contingency table\n",
    "        contingency_table = pd.crosstab(df[col], df[target_col])\n",
    "\n",
    "        # computes the chi-square statistic and p-value\n",
    "        chi_sq, p_val, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "        # append the results\n",
    "        result_dict[\"column_name\"].append(col)\n",
    "        result_dict[\"chi_sq\"].append(round(chi_sq, 2))\n",
    "        result_dict[\"p_val\"].append(round(p_val, 2))\n",
    "\n",
    "    # create a DataFrame from the results\n",
    "    result_df = pd.DataFrame(result_dict).sort_values(by=\"p_val\")\n",
    "    result_df[\"is_significant\"] = result_df[\"p_val\"] < 0.05\n",
    "\n",
    "    print(f\"Columns with/without a significant association to the column, {target_col}:\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DF showing chi-square and p-value statistics\n",
    "display_chi_square_columns(df, \"readmitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a class=\"anchor\" id=\"feature_engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_clip = [\"num_lab_procedures\"]\n",
    "cols_to_log = [\"num_medications\", \"num_procedures\", \"number_emergency\", \"number_inpatient\", \"number_outpatient\", \"time_in_hospital\"]\n",
    "\n",
    "# remove extreme outliers\n",
    "for col in cols_to_clip:\n",
    "    ninety_ninth_percentile = df[col].quantile(0.99)\n",
    "    df[f\"{col}_clipped\"] = df[col].where(df[col] <= ninety_ninth_percentile)\n",
    "\n",
    "# log transform some of the numeric columns\n",
    "for col in cols_to_log:\n",
    "    df[f\"{col}_log\"] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look again at the skew to see if it improved\n",
    "display_skewness_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a subset of the data\n",
    "numeric_features = [\"num_lab_procedures_clipped\", \"num_medications_log\", \"num_procedures_log\", \"number_diagnoses\", \"time_in_hospital_log\"]\n",
    "categorical_features = [\"admission_type_id\", \"age\", \"diabetesMed\", \"disease_class_1\", \"disease_class_2\", \"disease_class_3\", \"race\"]\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[\"readmitted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer([\n",
    "    (\"numeric\", StandardScaler(), numeric_features),\n",
    "    (\"categorical\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features)\n",
    "])\n",
    "\n",
    "# encode the categorical features and scale the numeric features\n",
    "X_train_processed = transformer.fit_transform(X_train)\n",
    "X_test_processed = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the feature names\n",
    "categorical_cols = transformer.named_transformers_[\"categorical\"].get_feature_names_out(categorical_features)\n",
    "numeric_cols = transformer.named_transformers_[\"numeric\"].get_feature_names_out(numeric_features)\n",
    "feature_cols = list(numeric_cols) + list(categorical_cols)\n",
    "\n",
    "# convert back to a DataFrame\n",
    "X_train_final = pd.DataFrame(X_train_processed, columns=feature_cols, index=X_train.index)\n",
    "X_test_final = pd.DataFrame(X_test_processed, columns=feature_cols, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y values to numeric\n",
    "y_train = y_train.map({\"NO\": 0, \"<30\": 1})\n",
    "y_test = y_test.map({\"NO\": 0, \"<30\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
